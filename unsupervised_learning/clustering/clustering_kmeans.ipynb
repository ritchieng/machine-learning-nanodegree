{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms\n",
    "- K-means\n",
    "- Single Link CLustering\n",
    "- Expectation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. K-means Algorithm**\n",
    "1. Assign\n",
    "    - We will choose cluster centers\n",
    "        - They are called centroids\n",
    "        - Choosing the initial location of the centroids would affect the final clustering results\n",
    "2. Optimize\n",
    "    - We will move the cluster centers to minimize the total bands' length\n",
    "        - The web connects the cluster center to the observations like a spider web\n",
    "            - So we want to minimize the total length of the web for each centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitations of K-means**\n",
    "- Suppose you use a fixed number of centroids and training set\n",
    "    - You would not get the same results\n",
    "    - It is highly dependent on where you put your centroids initially\n",
    "        - You might reach a local minima\n",
    "    - The more centroids you have, the more local minima you will have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Single Linkage Clustering (SLC)**\n",
    "- Consider each object a cluster (n objects)\n",
    "- Define intercluster distance as the distance between the closest two points in the two two clusters\n",
    "- Merge two closest clusters\n",
    "- Repeat n-k times to make k clusters\n",
    "    - In sum, it's just linking up the nearest points\n",
    "        - Just connect the dots to the nearest dots in a linear fashion\n",
    "\n",
    "**Running Time of SLC**\n",
    "- O(n^3) or slightly lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Soft Clustering**\n",
    "1. Select one of K Gaussians uniformly\n",
    "2. Sample x_i from that Gaussian\n",
    "3. Repeat n times\n",
    "4. Find a hypothesis that maximizes the probability of the data (maximum likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum Likelihood Gaussian**\n",
    "- The maximum likelihood mean of the Gaussian is the mean of the data\n",
    "\n",
    "**C. Expectation Maximization**\n",
    "- Similar to K-means\n",
    "- ![](cluster1.png)\n",
    "\n",
    "**Properties of Expectation Maximization**\n",
    "- Monotonically non-decreasing likelihood\n",
    "- Does not converge (practically does)\n",
    "- Will not diverge\n",
    "- Can get stuck in local optima\n",
    "    - Solution: randomly restart\n",
    "- Works with any distribution (if EM solvable)\n",
    "\n",
    "**Clustering Properties**\n",
    "<br \\> No clustering scheme (algorithm) that can achieve all three properties\n",
    "- Richness\n",
    "    - For any assignment of objects to clusters, there is some distance matrix D such that P_d, clustering scheme, returns that clustering\n",
    "        - There are multiple types of clustering\n",
    "- Scale-invariance\n",
    "    - Scaling distances by a positive value does not change the clustering\n",
    "    - Changing units (km to m)\n",
    "- Consistency\n",
    "    - Shrinking intracluster distances and expanding intercluster distances does not change the clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-means [clustering](http://scikit-learn.org/stable/modules/clustering.html) using scikit-learn**\n",
    "- **Hyperparameters available for tuning**\n",
    "    - n_clusters=8 \n",
    "        - This is what you can and should change\n",
    "    - max_iter=300\n",
    "        - This determines the number of iterations of:\n",
    "            1. Assign\n",
    "            2. Optimize (moving the centroids)\n",
    "    - n_init=10\n",
    "        - Number of times to initialize the algorithm\n",
    "        - If you think your data might need more initializations, you can increase this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], \n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore target names\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore feature names\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=1000, n_clusters=3, n_init=20,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate\n",
    "kmc = KMeans(n_clusters=3, max_iter=1000, n_init=20)\n",
    "\n",
    "# Fit\n",
    "kmc.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
